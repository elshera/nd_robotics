{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rover Project Notebook\n",
    "* Write new functions (or modify existing ones) to report and map out detections of obstacles and rock samples (yellow rocks)\n",
    "* Populate the `process_image()` function with the appropriate steps/functions to go from a raw image to a worldmap.\n",
    "* Run the cell that calls `process_image()` using `moviepy` functions to create video output\n",
    "* Once you have mapping working, move on to modifying `perception.py` and `decision.py` to allow your rover to navigate and map in autonomous mode!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get code highlighting in the markdown cells.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<style> code {background-color : orange !important;} </style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Configure the Notebook plotting style. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Import the necessary modules. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc                    # For saving images as needed\n",
    "import glob                          # For reading in a list of images from a folder\n",
    "import imageio\n",
    "import pandas as pd\n",
    "from moviepy.editor import ImageSequenceClip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local code\n",
    "import sys\n",
    "sys.path.append(\"./code\")\n",
    "import nd_functions as ndf\n",
    "import nd_classes as ndc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read in and display a random image from the `training_dataset` folder. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "outputExpanded": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = './training_dataset/IMG/*'\n",
    "\n",
    "# make a list of the frames saved during training mode\n",
    "img_list = glob.glob(path)\n",
    "print(\"Total of %d images in the list.\"%(len(img_list)))\n",
    "\n",
    "# Grab a random image from the list\n",
    "idx = np.random.randint(0, len(img_list)-1)\n",
    "\n",
    "# read in the picked immage\n",
    "image = mpimg.imread(img_list[idx])\n",
    "\n",
    "# print image size\n",
    "print(image.shape, image.shape[0], image.shape[1])\n",
    "\n",
    "# print some statistic\n",
    "print(image.min(), image.max(), image.mean())\n",
    "\n",
    "# show the image\n",
    "plt.imshow(image)\n",
    "\n",
    "# save the warped image\n",
    "scipy.misc.imsave('./output/picked_example.jpg', image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read in data for calibration. Display example grid and rock sample calibration images. Grid is needed for perspective transform and the rock image for creating a new color selection that identifies these samples so that can be picked up during autonomous navigation. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pointer to image files\n",
    "example_grid = './calibration_images/example_grid1.jpg'\n",
    "example_rock = './calibration_images/example_rock1.jpg'\n",
    "\n",
    "# load image from file pointer\n",
    "grid_img = mpimg.imread(example_grid)\n",
    "rock_img = mpimg.imread(example_rock)\n",
    "\n",
    "# plot images\n",
    "fig = plt.figure(figsize=(12,3))\n",
    "plt.subplot(121)\n",
    "plt.imshow(grid_img)\n",
    "plt.subplot(122)\n",
    "plt.imshow(rock_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Select the rock by thresholding it **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#select the rock from the environment\n",
    "rock_map = ndf.find_rocks(rock_img)\n",
    "\n",
    "fig = plt.figure(figsize=(12,3))\n",
    "plt.subplot(121)\n",
    "plt.imshow(rock_img)\n",
    "plt.subplot(122)\n",
    "plt.imshow(rock_map, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create warped immage. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These source and destination points are defined to warp the image to a grid where each 10x10 pixel square represents \n",
    "# 1 square meter\n",
    "\n",
    "# identify the coordinates in the image of the grid. \n",
    "source = np.float32([[14, 140], \n",
    "                     [301 ,140], \n",
    "                     [200, 96], \n",
    "                     [118, 96]\n",
    "                    ])\n",
    "\n",
    "# The destination box will be 2*dst_size on each side\n",
    "dst_size = 5 \n",
    "# Set a bottom offset to account for the fact that the bottom of the image is not the position of the rover but a bit in front of it\n",
    "bottom_offset = 6\n",
    "\n",
    "# identify the destination box\n",
    "destination = np.float32([[image.shape[1]/2 - dst_size, image.shape[0] - bottom_offset],\n",
    "                          [image.shape[1]/2 + dst_size, image.shape[0] - bottom_offset],\n",
    "                          [image.shape[1]/2 + dst_size, image.shape[0] - 2*dst_size - bottom_offset], \n",
    "                          [image.shape[1]/2 - dst_size, image.shape[0] - 2*dst_size - bottom_offset],\n",
    "                        ])\n",
    "\n",
    "# create warp immage and related mask\n",
    "warped, mask = ndf.perspect_transform(grid_img, source, destination)\n",
    "\n",
    "# save the warped image\n",
    "scipy.misc.imsave('./output/warped_example.jpg', warped)\n",
    "\n",
    "fig = plt.figure(figsize=(12,3))\n",
    "plt.subplot(121)\n",
    "plt.imshow(warped)\n",
    "plt.subplot(122)\n",
    "plt.imshow(mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Identify ground pixels only for navigable terrain and obstacles. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Using threshold of RGB > 160 as it does a nice job of identifying ground pixels only\n",
    "nav_map = ndf.color_thresh(warped)\n",
    "\n",
    "# create the obstacles map (inverting the nav_map mainly)\n",
    "obstacles_map = np.absolute(np.float32(nav_map) - 1) * mask\n",
    "\n",
    "#plt.imshow(nav_map, cmap='gray')\n",
    "scipy.misc.imsave('./output/warped_threshed.jpg', nav_map*255)\n",
    "\n",
    "fig = plt.figure(figsize=(12,3))\n",
    "plt.subplot(121)\n",
    "plt.imshow(obstacles_map, cmap='gray')\n",
    "plt.subplot(122)\n",
    "plt.imshow(nav_map, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Coordintate Transformations **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "outputExpanded": false
   },
   "outputs": [],
   "source": [
    "# Calculate pixel values in rover-centric coords. Since the thresh is in black and white, the trasformation will be on all the \n",
    "# pixesls in the white part. The returning valuea are 2 array x,y of all the pixels in white.... or highliting the navigable part.\n",
    "xpix, ypix = ndf.rover_coords(nav_map)\n",
    "\n",
    "# calculate distance/angle to all pixels. pixels are give as 2 arrays x,y.  \n",
    "dist, angles = ndf.to_polar_coords(xpix, ypix)\n",
    "\n",
    "# calculate mean angle from the set of angles. This correspondes to move in the meadle of the navigable terrain.\n",
    "mean_dir = np.mean(angles)\n",
    "\n",
    "# Do some plotting\n",
    "fig = plt.figure(figsize=(12,9))\n",
    "plt.subplot(221)\n",
    "plt.imshow(image)\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.imshow(warped)\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.imshow(nav_map, cmap='gray')\n",
    "\n",
    "plt.subplot(224)\n",
    "plt.plot(xpix, ypix, '.')\n",
    "plt.ylim(-160, 160)\n",
    "plt.xlim(0, 160)\n",
    "\n",
    "# draw an vector to indicate direction into the picture\n",
    "arrow_length = 100\n",
    "x_arrow = arrow_length * np.cos(mean_dir)\n",
    "y_arrow = arrow_length * np.sin(mean_dir)\n",
    "plt.arrow(0, 0, x_arrow, y_arrow, color='red', zorder=2, head_width=10, width=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read training dataset in pandas dataframe. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create data frame\n",
    "df = pd.read_csv('./training_dataset/robot_log.csv', delimiter=';', decimal=',')      \n",
    "\n",
    "# check some results\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Read in ground truth map and create a 3-channel image with it. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ground_truth = mpimg.imread('./calibration_images/map_bw.png')\n",
    "print(ground_truth.shape)\n",
    "ground_truth_3d = np.dstack((ground_truth*0, ground_truth*255, ground_truth*0)).astype(np.float)\n",
    "\n",
    "fig = plt.figure(figsize=(12,3))\n",
    "plt.subplot(121)\n",
    "plt.imshow(ground_truth_3d)\n",
    "plt.subplot(122)\n",
    "plt.imshow(ground_truth, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a data bucket **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create data object (Databucket) containing the training frames\n",
    "data = ndc.Databucket(df, ground_truth_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Make a video from processed image data. **  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create a clip from a list of images in the Databucket\n",
    "clip = ImageSequenceClip(data.images, fps=25) \n",
    "\n",
    "#  need to use the clip.fx method so that it can accept other arguments, clip.fl_image does nota ccept extra arguments\n",
    "new_clip = clip.fx(ndf.img_transformation, data, source, destination)\n",
    "\n",
    "# Define pathname to save the output video\n",
    "output = './output/training_mapping.mp4'\n",
    "%time new_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** inline video player **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
